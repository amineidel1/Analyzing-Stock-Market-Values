{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9edf0039",
   "metadata": {},
   "source": [
    "## Project Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21c65091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.9/dist-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-6712703b-b25c-4e78-a1f4-d62662ca8729;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.4.1 in central\n",
      "\tfound com.github.luben#zstd-jni;1.4.4-3 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.7.5 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      ":: resolution report :: resolve 762ms :: artifacts dl 34ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.luben#zstd-jni;1.4.4-3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.7.5 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-6712703b-b25c-4e78-a1f4-d62662ca8729\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 9 already retrieved (0kB/16ms)\n",
      "23/11/06 19:38:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MyApp\") \\\n",
    "    .config(\"spark.jars.packages\", 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0') \\\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fbe01c",
   "metadata": {},
   "source": [
    "Be sure to start the stream on Kafka!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ad65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType, TimestampType, DateType\n",
    "\n",
    "schema = StructType(\n",
    "      [\n",
    "        StructField(\"name\", StringType(), False),\n",
    "        StructField(\"price\", DoubleType(), False),\n",
    "        StructField(\"timestamp\", TimestampType(), False),\n",
    "      ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "494246ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_server = \"kafka1:9092\"   \n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "lines = (spark.readStream                        # Get the DataStreamReader\n",
    "  .format(\"kafka\")                                 # Specify the source format as \"kafka\"\n",
    "  .option(\"kafka.bootstrap.servers\", kafka_server) # Configure the Kafka server name and port\n",
    "  .option(\"subscribe\", \"stock\")                       # Subscribe to the \"en\" Kafka topic \n",
    "  .option(\"startingOffsets\", \"earliest\")           # The start point when a query is started\n",
    "  .option(\"maxOffsetsPerTrigger\", 100)             # Rate limit on max offsets per trigger interval\n",
    "  .load()\n",
    "  .select(from_json(col(\"value\").cast(\"string\"), schema).alias(\"parsed_value\"))\n",
    "# Load the DataFrame\n",
    ")\n",
    "df = lines.select(\"parsed_value.*\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ba52bf",
   "metadata": {},
   "source": [
    "## The assignment starts here\n",
    "\n",
    "You can create a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda443c",
   "metadata": {},
   "source": [
    "## Select the N most valuable stocks in a window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a2074fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/06 11:32:34 WARN StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-6ebfa87c-ee11-483b-a82d-b4dec7abde4d. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------+\n",
      "|              window| name|avgPrice|\n",
      "+--------------------+-----+--------+\n",
      "|[2023-10-28 20:12...|   RE|  128.37|\n",
      "|[2023-10-28 20:12...|  PXD|   128.0|\n",
      "|[2023-10-28 20:12...| WYNN|  120.24|\n",
      "|[2023-10-28 20:12...|  PVH|  114.07|\n",
      "|[2023-10-28 20:12...|  FRT|  106.58|\n",
      "|[2023-10-28 20:12...|  MTB|  104.87|\n",
      "|[2023-10-28 20:12...|BRK.B|  102.57|\n",
      "|[2023-10-28 20:12...|  AGN|   93.13|\n",
      "+--------------------+-----+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import window, avg\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "N = 8\n",
    "windowDuration = \"5 minutes\"\n",
    "slideDuration = \"2 minutes\"\n",
    "\n",
    "# Assign watermarks\n",
    "df_with_watermark = df.withWatermark(\"timestamp\", \"5 minutes\")\n",
    "\n",
    "# Group the data by the defined window and the stock name, then compute the average price for each group.\n",
    "topN_stocks_windowed = (df_with_watermark\n",
    "    .groupBy(\n",
    "        window(df_with_watermark.timestamp, windowDuration, slideDuration),\n",
    "        df_with_watermark.name)\n",
    "    .agg(avg(\"price\").alias(\"avgPrice\")))\n",
    "\n",
    "# Write the aggregated result into memory for querying\n",
    "query1 = (topN_stocks_windowed.writeStream\n",
    "    .outputMode(\"update\")\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"Aggr\")\n",
    "    .start())\n",
    "\n",
    "# Allow the above query to populate some data\n",
    "time.sleep(10)\n",
    "\n",
    "# Fetch top N stocks from the in-memory table\n",
    "result = spark.sql(f\"SELECT window, name, avgPrice FROM Aggr ORDER BY window DESC, avgPrice DESC LIMIT {N}\")\n",
    "\n",
    "# Show the result\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ecbee6",
   "metadata": {},
   "source": [
    "## Select the stocks that lost value between two windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52acc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/06 13:21:30 WARN StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-843acb5f-2c7e-4ff1-aa68-1338757dc5ce. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'XYL', 'AVY', 'HD', 'LB', 'CAG', 'CME'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'APA', 'SCG', 'LB', 'ORCL', 'TIF', 'KO', 'XYL', 'CLX', 'AEE', 'SLB', 'SBAC', 'HCP', 'AVY', 'HD', 'CBG', 'BEN', 'CAG', 'MPC', 'CME'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'APA', 'PHM', 'SCG', 'LB', 'ORCL', 'TIF', 'KO', 'XYL', 'BLL', 'CLX', 'AEE', 'SLB', 'SBAC', 'HCP', 'DHI', 'AVY', 'VRSK', 'HD', 'CBG', 'MAR', 'PEP', 'BEN', 'CAG', 'MPC', 'CME', 'ACN'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'XEL', 'APA', 'PHM', 'SCG', 'LB', 'ORCL', 'TIF', 'KO', 'MAA', 'XYL', 'BLL', 'CLX', 'AEE', 'SLB', 'SBAC', 'GIS', 'HCP', 'DHI', 'AVY', 'VRSK', 'HD', 'CBG', 'AMT', 'MAR', 'BXP', 'PEP', 'KMI', 'PPL', 'BEN', 'JNPR', 'CAG', 'MPC', 'CME', 'ACN', 'CCL', 'HCN'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'XEL', 'APA', 'PHM', 'SCG', 'T', 'LB', 'ORCL', 'TIF', 'MON', 'KO', 'MAA', 'XYL', 'BLL', 'CLX', 'AEE', 'SLB', 'AIV', 'SBAC', 'GIS', 'HCP', 'DHI', 'AVY', 'VRSK', 'HD', 'CBG', 'AMT', 'XOM', 'MAR', 'BXP', 'PEP', 'KMI', 'SPG', 'PPL', 'BEN', 'JNPR', 'CAG', 'MPC', 'CME', 'ACN', 'CCL', 'HCN', 'MAC'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'XEL', 'MCD', 'APA', 'PHM', 'SCG', 'T', 'LB', 'ORCL', 'TIF', 'MON', 'KO', 'MAA', 'XYL', 'BLL', 'UDR', 'CLX', 'AEE', 'SLB', 'AIV', 'SBAC', 'GIS', 'HCP', 'DHI', 'AVY', 'VRSK', 'HD', 'CBG', 'AMT', 'XOM', 'IBM', 'MAR', 'BXP', 'PEP', 'KMI', 'SPG', 'PPL', 'BEN', 'JNPR', 'NEM', 'CAG', 'MPC', 'CME', 'ACN', 'CCL', 'VTR', 'HCN', 'MAC'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'XEL', 'MCD', 'CHRW', 'APA', 'PHM', 'SCG', 'T', 'LB', 'ETR', 'ORCL', 'TIF', 'MON', 'KO', 'MAA', 'XYL', 'BLL', 'NTAP', 'UDR', 'CLX', 'AEE', 'SLB', 'AIV', 'SBAC', 'GIS', 'HCP', 'DHI', 'AVY', 'VRSK', 'WMB', 'HD', 'CBG', 'AMT', 'XOM', 'IBM', 'MAR', 'BXP', 'EW', 'PEP', 'KMI', 'SPG', 'PPL', 'BEN', 'JNPR', 'NEM', 'CAG', 'MPC', 'CME', 'ACN', 'CCL', 'VTR', 'CINF', 'HCN', 'MAC'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'XEL', 'MCD', 'CHRW', 'APA', 'PHM', 'SCG', 'T', 'MRO', 'ARE', 'LB', 'ETR', 'ORCL', 'CMS', 'TIF', 'MON', 'KO', 'MAA', 'XYL', 'BLL', 'NTAP', 'UDR', 'CLX', 'HUM', 'RE', 'AEE', 'SLB', 'AIV', 'SBAC', 'KR', 'RL', 'GIS', 'SO', 'HCP', 'DHI', 'O', 'ES', 'AVY', 'VRSK', 'WMB', 'HD', 'CBG', 'AMT', 'XOM', 'IBM', 'MAR', 'BXP', 'EW', 'PEP', 'KMI', 'SPG', 'PPL', 'FRT', 'BEN', 'JNPR', 'KSU', 'ED', 'NEM', 'CAG', 'MPC', 'CME', 'ACN', 'CCL', 'VTR', 'CINF', 'HCN', 'MAC'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'XEL', 'MCD', 'CHRW', 'APA', 'PHM', 'SCG', 'T', 'MRO', 'ARE', 'LB', 'ETR', 'ORCL', 'CMS', 'TIF', 'MON', 'KO', 'MAA', 'XYL', 'BLL', 'NTAP', 'UDR', 'CLX', 'HUM', 'RE', 'AEE', 'FOX', 'SLB', 'AIV', 'SBAC', 'KR', 'RL', 'GIS', 'SO', 'HCP', 'DHI', 'O', 'PH', 'ES', 'AVY', 'VRSK', 'WMB', 'HD', 'CBG', 'AMT', 'XOM', 'IBM', 'EQIX', 'SWK', 'MAR', 'BXP', 'EW', 'PEP', 'AMD', 'KMI', 'SPG', 'PPL', 'FRT', 'COTY', 'BEN', 'IRM', 'JNPR', 'KSU', 'ED', 'NEM', 'CAG', 'MPC', 'CME', 'ACN', 'CCL', 'VTR', 'CINF', 'HCN', 'MAC'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MCD', 'SCG', 'CTXS', 'T', 'MRO', 'LB', 'ETR', 'ORCL', 'CMS', 'NTAP', 'HUM', 'SBAC', 'O', 'VRSK', 'AMT', 'IBM', 'EQIX', 'DG', 'BXP', 'EW', 'FRT', 'NEM', 'CHRW', 'PHM', 'CNP', 'ARE', 'MON', 'KO', 'C', 'UDR', 'SLB', 'KR', 'HCP', 'DHI', 'ES', 'AVY', 'XOM', 'MAR', 'DOV', 'PEP', 'FE', 'PPL', 'IRM', 'BEN', 'MPC', 'CME', 'CINF', 'MAC', 'XEL', 'APA', 'MAA', 'XYL', 'BLL', 'CLX', 'AEE', 'AIV', 'RL', 'GIS', 'SO', 'WMB', 'CBG', 'SWK', 'AMD', 'SPG', 'COTY', 'JNPR', 'ED', 'CAG', 'ACN', 'CCL', 'TIF', 'RE', 'FOX', 'VZ', 'PH', 'HD', 'DISCA', 'KMI', 'KSU', 'RSG', 'HCN', 'VTR'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MCD', 'SCG', 'CTXS', 'DLR', 'T', 'MRO', 'LB', 'ETR', 'ORCL', 'CMS', 'NTAP', 'HUM', 'SBAC', 'O', 'VRSK', 'AMT', 'IBM', 'EQIX', 'DG', 'GPS', 'BXP', 'EW', 'FRT', 'NEM', 'CHRW', 'PHM', 'CNP', 'ARE', 'ZTS', 'MON', 'KO', 'C', 'SRCL', 'UDR', 'SLB', 'KR', 'HCP', 'DHI', 'ES', 'AVY', 'XOM', 'MAR', 'DOV', 'PEP', 'FE', 'PPL', 'IRM', 'BEN', 'MPC', 'CME', 'CINF', 'MAC', 'XEL', 'APA', 'UHS', 'MAA', 'XYL', 'BLL', 'CLX', 'AEE', 'AIV', 'RL', 'GIS', 'SO', 'WMB', 'CBG', 'SWK', 'AMD', 'SPG', 'COTY', 'JNPR', 'ED', 'CAG', 'ACN', 'CCL', 'TIF', 'MAT', 'RE', 'FOX', 'VZ', 'PH', 'HD', 'DISCA', 'KMI', 'KSU', 'RSG', 'HCN', 'VTR'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MCD', 'SCG', 'CTXS', 'DLR', 'T', 'MRO', 'LB', 'ETR', 'ORCL', 'CMS', 'NTAP', 'HUM', 'SBAC', 'O', 'VRSK', 'AMT', 'IBM', 'EQIX', 'DG', 'GPS', 'BXP', 'EW', 'FRT', 'NEM', 'CHRW', 'PHM', 'CNP', 'ARE', 'ZTS', 'BAC', 'MON', 'KO', 'C', 'SRCL', 'UDR', 'ZION', 'PGR', 'SLB', 'KR', 'HCP', 'DHI', 'ES', 'AVY', 'XOM', 'MAR', 'DOV', 'PEP', 'FE', 'PPL', 'IRM', 'BEN', 'MPC', 'CME', 'CINF', 'MAC', 'XEL', 'APA', 'UHS', 'MAA', 'XYL', 'BLL', 'CLX', 'AEE', 'AIV', 'RL', 'GIS', 'SO', 'WMB', 'CBG', 'SWK', 'AMD', 'SPG', 'COTY', 'JNPR', 'ED', 'CAG', 'ACN', 'CCL', 'ANSS', 'ULTA', 'TIF', 'MAT', 'RE', 'FOX', 'VZ', 'PH', 'HD', 'DISCA', 'KMI', 'KSU', 'RSG', 'HCN', 'VTR'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MCD', 'SCG', 'CTXS', 'DLR', 'OMC', 'T', 'MRO', 'LB', 'ETR', 'ORCL', 'CMS', 'NTAP', 'HUM', 'SBAC', 'O', 'BSX', 'VRSK', 'TJX', 'AMT', 'IBM', 'EQIX', 'DG', 'GPS', 'BXP', 'EW', 'PVH', 'FRT', 'MKC', 'NEM', 'CHRW', 'PHM', 'CNP', 'ARE', 'ZTS', 'BAC', 'MON', 'KO', 'C', 'SRCL', 'JPM', 'STT', 'UDR', 'ZION', 'PGR', 'SLB', 'KR', 'EXC', 'HCP', 'DHI', 'ES', 'AVY', 'XOM', 'MAR', 'DOV', 'PEP', 'CA', 'FE', 'PPL', 'IRM', 'BEN', 'MPC', 'CME', 'CINF', 'MAC', 'XEL', 'APA', 'UHS', 'MAA', 'LOW', 'XYL', 'BLL', 'CLX', 'AEE', 'LKQ', 'AIV', 'RL', 'GIS', 'SO', 'WMB', 'CBG', 'SWK', 'FLR', 'WU', 'AMD', 'SPG', 'COTY', 'BAX', 'JNPR', 'ED', 'CAG', 'ACN', 'PNW', 'CCL', 'ANSS', 'NOV', 'ULTA', 'TIF', 'CSCO', 'MAT', 'RE', 'FOX', 'VZ', 'PH', 'HD', 'DISCA', 'KMI', 'KSU', 'RSG', 'HCN', 'VTR'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MCD', 'SCG', 'CTXS', 'DLR', 'OMC', 'T', 'VRSN', 'MRO', 'LB', 'ETR', 'ORCL', 'CMS', 'PKG', 'NTAP', 'HUM', 'SBAC', 'O', 'BSX', 'VRSK', 'K', 'TJX', 'AMT', 'IBM', 'EQIX', 'DG', 'GPS', 'BXP', 'EW', 'PVH', 'FRT', 'MKC', 'NEM', 'RHT', 'CHRW', 'PHM', 'CNP', 'ARE', 'ZTS', 'BAC', 'MON', 'KO', 'C', 'SRCL', 'JPM', 'STT', 'UDR', 'ZION', 'PGR', 'SLB', 'KR', 'EXC', 'HCP', 'DHI', 'ES', 'AVY', 'XOM', 'MAR', 'DOV', 'PEP', 'CA', 'FE', 'PPL', 'IRM', 'BEN', 'MPC', 'CME', 'CINF', 'MAC', 'XEL', 'APA', 'RJF', 'UHS', 'MAA', 'LOW', 'XYL', 'BLL', 'CLX', 'ALXN', 'AEE', 'LKQ', 'AIV', 'RL', 'DE', 'GIS', 'SO', 'HSY', 'MOS', 'WMB', 'CBG', 'SWK', 'FLR', 'WU', 'AMD', 'SPG', 'COTY', 'BAX', 'JNPR', 'ED', 'CAG', 'ACN', 'PNW', 'CCL', 'ANSS', 'NOV', 'ULTA', 'TIF', 'CSCO', 'MAT', 'RE', 'FOX', 'VZ', 'PH', 'HD', 'DISCA', 'KMI', 'KSU', 'RSG', 'HCN', 'VTR'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MCD', 'EL', 'SCG', 'CTXS', 'DLR', 'OMC', 'T', 'VRSN', 'MRO', 'LB', 'ETR', 'ORCL', 'CMS', 'PKG', 'PG', 'NTAP', 'HUM', 'SBAC', 'O', 'BSX', 'VRSK', 'K', 'TJX', 'AMT', 'IBM', 'EQIX', 'DG', 'GPN', 'GPS', 'CTSH', 'BXP', 'EW', 'PVH', 'FRT', 'MKC', 'NEM', 'RHT', 'CHRW', 'PHM', 'CNP', 'ARE', 'ZTS', 'BAC', 'MON', 'KO', 'C', 'SRCL', 'JPM', 'STT', 'UDR', 'ZION', 'PGR', 'SLB', 'KR', 'EXC', 'HCP', 'DHI', 'PDCO', 'ES', 'AVY', 'XOM', 'MAR', 'DOV', 'PEP', 'CA', 'FE', 'PPL', 'IRM', 'BEN', 'MPC', 'CME', 'CINF', 'MAC', 'XEL', 'APA', 'RJF', 'CBOE', 'UHS', 'MAA', 'LOW', 'XYL', 'BLL', 'CLX', 'ALXN', 'AEE', 'LKQ', 'AIV', 'RL', 'DE', 'GIS', 'SO', 'HSY', 'MOS', 'WMB', 'CBG', 'SWK', 'FLR', 'WU', 'ORLY', 'AMD', 'SPG', 'COTY', 'BAX', 'JNPR', 'ED', 'CAG', 'ACN', 'PNW', 'CCL', 'ANSS', 'NOV', 'ULTA', 'TIF', 'CSCO', 'MAT', 'RE', 'FOX', 'VZ', 'CERN', 'PH', 'HD', 'DISCA', 'FBHS', 'LEN', 'KMI', 'KSU', 'RSG', 'HCN', 'VTR'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MCD', 'EL', 'SCG', 'CTXS', 'DLR', 'OMC', 'T', 'VRSN', 'MRO', 'LB', 'ETR', 'ORCL', 'CMS', 'PKG', 'PG', 'NTAP', 'HUM', 'SBAC', 'O', 'BSX', 'VRSK', 'K', 'TJX', 'AMT', 'IBM', 'EQIX', 'DG', 'GPN', 'GPS', 'CTSH', 'BXP', 'EW', 'PVH', 'FRT', 'MKC', 'NEM', 'RHT', 'CHRW', 'PHM', 'CNP', 'ARE', 'ZTS', 'BAC', 'MON', 'KO', 'C', 'SRCL', 'JPM', 'STT', 'UDR', 'ZION', 'PGR', 'SLB', 'VIAB', 'KR', 'EXC', 'HCP', 'DHI', 'PDCO', 'ES', 'AVY', 'XOM', 'HP', 'MAR', 'DOV', 'PEP', 'CA', 'FE', 'PPL', 'IRM', 'BEN', 'MPC', 'CME', 'CINF', 'MAC', 'XEL', 'APA', 'XLNX', 'RJF', 'CBOE', 'UHS', 'MAA', 'LOW', 'XYL', 'BLL', 'CLX', 'ALXN', 'AEE', 'LKQ', 'AIV', 'RL', 'DE', 'GIS', 'SO', 'HSY', 'MOS', 'WMB', 'CBG', 'SWK', 'FLR', 'WU', 'ORLY', 'COP', 'AMD', 'SPG', 'COTY', 'BAX', 'JNPR', 'ED', 'CAG', 'ACN', 'PNW', 'CCL', 'ADI', 'ANSS', 'NOV', 'ULTA', 'GE', 'A', 'FITB', 'TIF', 'CSCO', 'MAT', 'AFL', 'RE', 'FOX', 'VZ', 'CERN', 'GM', 'PH', 'HD', 'DISCA', 'FBHS', 'LEN', 'KMI', 'KSU', 'RSG', 'ETN', 'HCN', 'VTR'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MCD', 'EL', 'SCG', 'CTXS', 'DLR', 'OMC', 'T', 'VRSN', 'MRO', 'LB', 'ETR', 'ORCL', 'CMS', 'PKG', 'FLIR', 'PG', 'NTAP', 'HUM', 'LLL', 'SBAC', 'O', 'BSX', 'VRSK', 'K', 'TJX', 'AMT', 'IBM', 'EQIX', 'DG', 'GPN', 'GPS', 'CTSH', 'BXP', 'EW', 'PVH', 'FRT', 'MKC', 'NEM', 'BWA', 'RHT', 'CHRW', 'PHM', 'CNP', 'ARE', 'ZTS', 'BAC', 'MON', 'KO', 'C', 'SRCL', 'JPM', 'LNC', 'STT', 'UDR', 'ZION', 'UTX', 'PGR', 'SLB', 'VIAB', 'KR', 'EXC', 'HCP', 'DHI', 'PDCO', 'ES', 'AVY', 'TGT', 'XOM', 'HP', 'MAR', 'DOV', 'PEP', 'CA', 'FE', 'PPL', 'IRM', 'BEN', 'MPC', 'CME', 'CINF', 'PCAR', 'MAC', 'XEL', 'APA', 'XLNX', 'RJF', 'CBOE', 'UHS', 'MAA', 'LOW', 'XYL', 'BLL', 'CLX', 'ALXN', 'AEE', 'LKQ', 'AIV', 'RL', 'DE', 'GIS', 'SO', 'HSY', 'MOS', 'WMB', 'CBG', 'SWK', 'FLR', 'WU', 'GWW', 'ORLY', 'COP', 'AMD', 'SPG', 'COTY', 'KIM', 'BAX', 'JNPR', 'ED', 'CAG', 'ACN', 'PNW', 'CCL', 'ADI', 'ANSS', 'NOV', 'ULTA', 'GE', 'A', 'FITB', 'TIF', 'CSCO', 'MAT', 'UPS', 'AFL', 'RE', 'FOX', 'F', 'VZ', 'CERN', 'GM', 'PH', 'HD', 'DISCA', 'FBHS', 'LEN', 'KMI', 'KSU', 'RSG', 'ETN', 'HCN', 'VTR'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MCD', 'EL', 'SCG', 'CTXS', 'DLR', 'OMC', 'T', 'VRSN', 'PNR', 'MRO', 'LB', 'ETR', 'ORCL', 'CMS', 'PKG', 'FLIR', 'PG', 'MDLZ', 'NTAP', 'HUM', 'LLL', 'SBAC', 'O', 'BSX', 'VRSK', 'K', 'TJX', 'AMT', 'IBM', 'EQIX', 'DG', 'GPN', 'GPS', 'CTSH', 'BXP', 'EW', 'PVH', 'FRT', 'MKC', 'NEM', 'BWA', 'NBL', 'EMN', 'RHT', 'COF', 'CHRW', 'PHM', 'CNP', 'ARE', 'ZTS', 'CMA', 'BAC', 'MON', 'KO', 'C', 'SRCL', 'JPM', 'LNC', 'STT', 'UDR', 'ZION', 'UTX', 'PGR', 'SLB', 'VIAB', 'KR', 'EXC', 'HCP', 'DHI', 'PDCO', 'PRU', 'ES', 'AVY', 'TGT', 'XOM', 'PKI', 'CPB', 'HP', 'MAR', 'DOV', 'CVX', 'PEP', 'CA', 'FE', 'PPL', 'IRM', 'BEN', 'FLS', 'MPC', 'CME', 'CINF', 'PCAR', 'MAC', 'XEL', 'APA', 'XLNX', 'RJF', 'CBOE', 'PWR', 'MCHP', 'UHS', 'MAA', 'LOW', 'XYL', 'BLL', 'CHK', 'CLX', 'ALXN', 'AEE', 'LKQ', 'EMR', 'AIV', 'RL', 'DE', 'GIS', 'SO', 'HSY', 'MOS', 'WMB', 'CBG', 'SWK', 'FLR', 'WU', 'GWW', 'ORLY', 'COP', 'AMD', 'SPG', 'COTY', 'KIM', 'BAX', 'JNPR', 'ED', 'CAG', 'ACN', 'PNW', 'CCL', 'ADI', 'ANSS', 'NOV', 'ULTA', 'GE', 'A', 'FITB', 'TIF', 'CSCO', 'NWS', 'MAT', 'UPS', 'AFL', 'RE', 'FOX', 'F', 'VZ', 'CERN', 'GM', 'PH', 'GRMN', 'HD', 'DISCA', 'RRC', 'FBHS', 'LEN', 'KMI', 'KSU', 'RSG', 'ETN', 'HCN', 'VTR'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MCD', 'EL', 'SCG', 'CTXS', 'DLR', 'OMC', 'T', 'VRSN', 'PNR', 'MRO', 'LB', 'ETR', 'FAST', 'ORCL', 'CMS', 'PKG', 'FLIR', 'PG', 'MDLZ', 'NTAP', 'HUM', 'LLL', 'SBAC', 'O', 'BSX', 'VRSK', 'K', 'TJX', 'AMT', 'IBM', 'EQIX', 'DG', 'GPN', 'GPS', 'CTSH', 'BXP', 'EW', 'PVH', 'FRT', 'MKC', 'NEM', 'BWA', 'NBL', 'EMN', 'RHT', 'COF', 'CHRW', 'PHM', 'CNP', 'ARE', 'ZTS', 'CMA', 'BAC', 'MON', 'KO', 'C', 'SRCL', 'JPM', 'LNC', 'STT', 'UDR', 'ZION', 'UTX', 'PGR', 'SLB', 'FTI', 'VIAB', 'KR', 'EXC', 'HCP', 'DHI', 'PDCO', 'PRU', 'ES', 'AVY', 'TGT', 'XOM', 'PKI', 'CPB', 'HP', 'MLM', 'MAR', 'DOV', 'CVX', 'PEP', 'CA', 'FE', 'PPL', 'IRM', 'BEN', 'FLS', 'MPC', 'CME', 'CINF', 'PCAR', 'MAC', 'XEL', 'APA', 'SNI', 'XLNX', 'RJF', 'KORS', 'CBOE', 'PWR', 'MCHP', 'UHS', 'MAA', 'LOW', 'XYL', 'BLL', 'CHK', 'CLX', 'ALXN', 'AEE', 'LKQ', 'EMR', 'AIV', 'RL', 'DE', 'GIS', 'SO', 'HSY', 'MOS', 'WMB', 'CBG', 'SWK', 'FLR', 'WU', 'GWW', 'ORLY', 'COP', 'AMD', 'SPG', 'COTY', 'KIM', 'BAX', 'JNPR', 'ED', 'CAG', 'ACN', 'PNW', 'CCL', 'ADI', 'ANSS', 'NOV', 'ULTA', 'GE', 'A', 'FITB', 'TIF', 'CSCO', 'NWS', 'MAT', 'UPS', 'AFL', 'RE', 'FOX', 'F', 'VZ', 'CERN', 'GM', 'PH', 'GRMN', 'HD', 'DISCA', 'RRC', 'FBHS', 'LEN', 'KMI', 'KSU', 'RSG', 'ETN', 'HCN', 'VTR'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MCD', 'EL', 'CMI', 'SCG', 'CTXS', 'DLR', 'OMC', 'T', 'VRSN', 'PNR', 'MRO', 'LB', 'ETR', 'FAST', 'ORCL', 'CMS', 'PKG', 'FLIR', 'PG', 'MDLZ', 'NTAP', 'HUM', 'LLL', 'SBAC', 'O', 'BSX', 'VRSK', 'K', 'TJX', 'AMT', 'IBM', 'EQIX', 'DG', 'GPN', 'GPS', 'CTSH', 'BXP', 'EW', 'PVH', 'FRT', 'MKC', 'NEM', 'BWA', 'NBL', 'EMN', 'RHT', 'COF', 'CHRW', 'PHM', 'CNP', 'ARE', 'ZTS', 'CMA', 'BAC', 'MON', 'KO', 'C', 'SRCL', 'JPM', 'LNC', 'STT', 'UDR', 'ZION', 'UTX', 'PGR', 'SLB', 'FTI', 'VIAB', 'KR', 'EXC', 'HCP', 'DHI', 'PDCO', 'PRU', 'ES', 'AVY', 'TGT', 'XOM', 'PKI', 'ALB', 'CPB', 'HP', 'MLM', 'MAR', 'DOV', 'CVX', 'PEP', 'CA', 'FMC', 'FE', 'PPL', 'IRM', 'BEN', 'FLS', 'MPC', 'CME', 'CINF', 'PCAR', 'CAT', 'MAC', 'XEL', 'APA', 'SNI', 'XLNX', 'RJF', 'KORS', 'OKE', 'CBOE', 'PWR', 'MCHP', 'UHS', 'MAA', 'LOW', 'XYL', 'BLL', 'CHK', 'CLX', 'ALXN', 'AEE', 'LKQ', 'EMR', 'ALLE', 'HRS', 'AIV', 'RL', 'DE', 'GIS', 'SO', 'HSY', 'MOS', 'WMB', 'CBG', 'SWK', 'FLR', 'WU', 'GWW', 'ORLY', 'COP', 'AMD', 'SPG', 'COTY', 'KIM', 'BAX', 'JNPR', 'ED', 'LUK', 'CAG', 'ACN', 'PNW', 'CCL', 'CRM', 'ADI', 'ANSS', 'NOV', 'ULTA', 'GE', 'A', 'FITB', 'TIF', 'CSCO', 'NWS', 'MAT', 'UPS', 'AFL', 'RE', 'FOX', 'F', 'VZ', 'CERN', 'GM', 'PH', 'GRMN', 'HD', 'DISCA', 'RRC', 'FBHS', 'WYNN', 'LEN', 'KMI', 'KSU', 'RSG', 'ETN', 'HCN', 'VTR'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MCD', 'EL', 'CMI', 'SCG', 'CTXS', 'DLR', 'OMC', 'T', 'VRSN', 'PNR', 'MRO', 'LB', 'ETR', 'FAST', 'ORCL', 'CMS', 'PKG', 'FLIR', 'PG', 'MDLZ', 'NTAP', 'HUM', 'LLL', 'SBAC', 'O', 'BSX', 'VRSK', 'K', 'TJX', 'AMT', 'IBM', 'EQIX', 'DG', 'GPN', 'GPS', 'CTSH', 'BXP', 'EW', 'PVH', 'FRT', 'MKC', 'NEM', 'BWA', 'NBL', 'EMN', 'RHT', 'COF', 'CHRW', 'PHM', 'CNP', 'ARE', 'ZTS', 'CMA', 'BAC', 'MON', 'KO', 'C', 'SRCL', 'JPM', 'LNC', 'STT', 'UDR', 'ZION', 'UTX', 'PGR', 'SLB', 'FTI', 'VIAB', 'KR', 'EXC', 'HCP', 'DHI', 'PDCO', 'PRU', 'ES', 'AVY', 'TGT', 'XOM', 'PKI', 'ALB', 'CPB', 'HP', 'MLM', 'MAR', 'DOV', 'CVX', 'PEP', 'CA', 'FMC', 'FE', 'PPL', 'IRM', 'BEN', 'FLS', 'MPC', 'CME', 'CINF', 'PCAR', 'CAT', 'MAC', 'XEL', 'APA', 'SNI', 'XLNX', 'RJF', 'KORS', 'OKE', 'CBOE', 'PWR', 'MCHP', 'UHS', 'MAA', 'LOW', 'XYL', 'BLL', 'CHK', 'CLX', 'ALXN', 'AEE', 'LKQ', 'EMR', 'ALLE', 'HRS', 'AIV', 'RL', 'DE', 'GOOGL', 'GIS', 'SO', 'HSY', 'MOS', 'WMB', 'CBG', 'SWK', 'FLR', 'WU', 'GWW', 'ORLY', 'HAL', 'COP', 'AMD', 'SPG', 'COTY', 'KIM', 'BAX', 'JNPR', 'ED', 'LUK', 'CAG', 'ACN', 'PNW', 'CCL', 'CRM', 'ADI', 'ANSS', 'NOV', 'ULTA', 'GE', 'CMG', 'A', 'FITB', 'TIF', 'CSCO', 'NWS', 'MAT', 'UPS', 'AFL', 'RE', 'FOX', 'F', 'VZ', 'CERN', 'GM', 'PH', 'GRMN', 'HD', 'KLAC', 'DISCA', 'RRC', 'FBHS', 'WYNN', 'LEN', 'KMI', 'KSU', 'RSG', 'ETN', 'HCN', 'VTR'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MCD', 'EL', 'CMI', 'SCG', 'CTXS', 'DLR', 'OMC', 'T', 'VRSN', 'PNR', 'MRO', 'LB', 'ETR', 'FAST', 'ORCL', 'CMS', 'PKG', 'FLIR', 'PG', 'MDLZ', 'NTAP', 'HUM', 'DISCK', 'LLL', 'PX', 'SBAC', 'O', 'BSX', 'VRSK', 'K', 'TJX', 'AMT', 'IBM', 'EQIX', 'DG', 'GPN', 'GPS', 'CTSH', 'BXP', 'EW', 'PVH', 'FRT', 'MKC', 'NEM', 'BWA', 'NBL', 'EMN', 'RHT', 'COF', 'CHRW', 'PHM', 'CNP', 'ARE', 'ZTS', 'CMA', 'BAC', 'MON', 'KO', 'C', 'DVN', 'SRCL', 'JPM', 'LNC', 'STT', 'UDR', 'ZION', 'UTX', 'PGR', 'JNJ', 'SLB', 'FTI', 'VIAB', 'KR', 'EXC', 'HCP', 'DHI', 'PDCO', 'PRU', 'ES', 'AVY', 'TGT', 'XOM', 'PKI', 'ALB', 'CPB', 'HP', 'MLM', 'MAR', 'DOV', 'CVX', 'PEP', 'CA', 'FMC', 'FE', 'PPL', 'IRM', 'BEN', 'FLS', 'MPC', 'CME', 'CINF', 'PCAR', 'CAT', 'MAC', 'XEL', 'APA', 'SNI', 'XLNX', 'RJF', 'KORS', 'OKE', 'CBOE', 'PWR', 'MCHP', 'HOG', 'UHS', 'MAA', 'LOW', 'XYL', 'BLL', 'CHK', 'CLX', 'ALXN', 'AEE', 'LKQ', 'EMR', 'ALLE', 'HRS', 'AIV', 'RL', 'DE', 'GOOGL', 'GIS', 'SO', 'HSY', 'MOS', 'WMB', 'CBG', 'SWK', 'FLR', 'WU', 'GWW', 'ORLY', 'HAL', 'COP', 'AMD', 'SPG', 'COTY', 'KIM', 'BAX', 'JNPR', 'ED', 'LUK', 'CAG', 'ACN', 'PNW', 'CCL', 'EQT', 'CRM', 'ADI', 'ANSS', 'NOV', 'ULTA', 'GE', 'CMG', 'A', 'FITB', 'TIF', 'CSCO', 'ISRG', 'NWS', 'MAT', 'ROK', 'UPS', 'AFL', 'RE', 'FOX', 'F', 'VZ', 'CERN', 'GM', 'PH', 'GRMN', 'HD', 'KLAC', 'DISCA', 'RRC', 'FBHS', 'WYNN', 'LEN', 'QCOM', 'KMI', 'KSU', 'RSG', 'ETN', 'HCN', 'VTR'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MCD', 'EL', 'CMI', 'SCG', 'CTXS', 'DLR', 'OMC', 'T', 'VRSN', 'PNR', 'MRO', 'LB', 'ETR', 'FAST', 'ORCL', 'CMS', 'PKG', 'FLIR', 'PG', 'MDLZ', 'NTAP', 'HUM', 'DISCK', 'LLL', 'PX', 'SBAC', 'O', 'BSX', 'VRSK', 'K', 'TJX', 'AMT', 'IBM', 'EQIX', 'DG', 'GPN', 'GPS', 'CTSH', 'APC', 'BXP', 'EW', 'PVH', 'FRT', 'MKC', 'NEM', 'BWA', 'NBL', 'EMN', 'RHT', 'COF', 'CHRW', 'PHM', 'CNP', 'ARE', 'ZTS', 'CMA', 'BAC', 'MON', 'KO', 'C', 'DVN', 'SRCL', 'JPM', 'LNC', 'STT', 'UDR', 'ZION', 'UTX', 'PGR', 'JNJ', 'SLB', 'FTI', 'VIAB', 'KR', 'EXC', 'HCP', 'DHI', 'PDCO', 'PRU', 'ES', 'AVY', 'TGT', 'CVS', 'XOM', 'PKI', 'ALB', 'AIZ', 'CPB', 'HP', 'MLM', 'ABBV', 'MAR', 'DOV', 'CVX', 'PEP', 'CA', 'FMC', 'FE', 'PPL', 'IRM', 'BEN', 'FLS', 'MPC', 'CME', 'CINF', 'PCAR', 'CAT', 'MAC', 'XEL', 'RF', 'APA', 'SNI', 'XLNX', 'RJF', 'KORS', 'OKE', 'CBOE', 'PWR', 'MCHP', 'HOG', 'UHS', 'MAA', 'LOW', 'XYL', 'BLL', 'CHK', 'CLX', 'ALXN', 'AEE', 'LKQ', 'EMR', 'ALLE', 'HRS', 'AIV', 'RL', 'DE', 'GOOGL', 'GIS', 'SO', 'HSY', 'CF', 'MOS', 'WMB', 'CBG', 'SWK', 'FLR', 'HRB', 'WU', 'GWW', 'ORLY', 'HAL', 'COP', 'AMD', 'SPG', 'COTY', 'KIM', 'BAX', 'SYMC', 'JNPR', 'ED', 'LUK', 'CAG', 'ACN', 'PNW', 'CCL', 'EQT', 'CRM', 'ADI', 'ANSS', 'NOV', 'ULTA', 'GE', 'CMG', 'A', 'FITB', 'ANDV', 'TIF', 'CSCO', 'PXD', 'ISRG', 'NWS', 'MAT', 'ROK', 'UPS', 'AFL', 'RE', 'FOX', 'F', 'VZ', 'CERN', 'GM', 'PH', 'GRMN', 'HD', 'KLAC', 'DISCA', 'RRC', 'FBHS', 'WYNN', 'LEN', 'QCOM', 'KMI', 'KSU', 'RSG', 'ETN', 'HCN', 'VTR'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/06 13:22:45 WARN StateStore: Error running maintenance thread\n",
      "java.lang.IllegalStateException: SparkEnv not active, cannot do maintenance on StateStores\n",
      "\tat org.apache.spark.sql.execution.streaming.state.StateStore$.doMaintenance(StateStore.scala:422)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.StateStore$.$anonfun$startMaintenanceIfNeeded$1(StateStore.scala:408)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.StateStore$MaintenanceTask$$anon$1.run(StateStore.scala:324)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import window, col, last\n",
    "from pyspark.sql.types import StringType, DoubleType, StructType, StructField, TimestampType\n",
    "\n",
    "# Use a dictionary to hold the state of each stock\n",
    "stock_states = {}\n",
    "# Set to hold names of stocks that lost value\n",
    "stocks_that_lost_value = set()\n",
    "\n",
    "# Define a class to hold the state of each stock\n",
    "class StockState:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.last_price = None\n",
    "        self.last_window_end = None\n",
    "        self.lost_value = False  # Add a flag to track if the stock lost value\n",
    "\n",
    "    def update(self, price, window_end):\n",
    "        if self.last_window_end is None or window_end > self.last_window_end:\n",
    "            if self.last_price is not None and price < self.last_price:\n",
    "                self.lost_value = True  # Stock lost value\n",
    "                stocks_that_lost_value.add(self.name)\n",
    "            else:\n",
    "                self.lost_value = False  # Stock did not lose value\n",
    "            self.last_price = price\n",
    "            self.last_window_end = window_end\n",
    "        # Return the state including whether the stock lost value\n",
    "        return (self.name, self.last_price, self.last_window_end, self.lost_value)\n",
    "\n",
    "\n",
    "# Define the watermark and window operation on the streaming DataFrame\n",
    "windowedDF = df \\\n",
    "    .withWatermark(\"timestamp\", \"10 minutes\") \\\n",
    "    .groupBy(\n",
    "        col(\"name\"),\n",
    "        window(col(\"timestamp\"), \"5 minutes\")\n",
    "    ) \\\n",
    "    .agg(\n",
    "        last(\"price\").alias(\"last_price\")\n",
    "    )\n",
    "\n",
    "def process_batch(df, epoch_id):\n",
    "    # Process the DataFrame row by row\n",
    "    for row in df.collect():\n",
    "        stock_name = row['name']\n",
    "        price = row['last_price']\n",
    "        window_end = row['window'].end\n",
    "\n",
    "        # Get the stock state or create it if it doesn't exist\n",
    "        stock_state = stock_states.get(stock_name, StockState(stock_name))\n",
    "\n",
    "        # Update the state and check if the stock lost value\n",
    "        result = stock_state.update(price, window_end)\n",
    "        stock_states[stock_name] = stock_state  # Update the state in the dictionary\n",
    "\n",
    "    print(stocks_that_lost_value)\n",
    "\n",
    "# Define the streaming query using the process_batch function\n",
    "query = windowedDF.writeStream \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .foreachBatch(process_batch) \\\n",
    "    .start()  # Start the streaming query\n",
    "\n",
    "# Await termination of the streaming query (this is running continuously)\n",
    "query.awaitTermination(timeout=60)\n",
    "query.stop()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3fd87b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/06 11:38:28 WARN StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-505e894d-1478-4ff9-9639-a5fc214c1877. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "[Stage 479:(184 + 8) / 200][Stage 481:>  (0 + 0) / 1][Stage 483:>(0 + 0) / 200] \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----------+\n",
      "|name|avgPrice|priceChange|\n",
      "+----+--------+-----------+\n",
      "| PPG|  69.885|        0.0|\n",
      "| WEC|    39.9|        0.0|\n",
      "| HAS|   40.93|        0.0|\n",
      "| PNW|   54.63|        0.0|\n",
      "|KORS|   64.04|        0.0|\n",
      "| TEL|   41.17|        0.0|\n",
      "| EOG|   63.53|        0.0|\n",
      "| DHR|   61.46|        0.0|\n",
      "+----+--------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc47d45e",
   "metadata": {},
   "source": [
    "## Select the stock that gained the most (between windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ebcdd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/06 12:37:43 WARN StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-2d65840a-7d43-4962-90ef-bcebd3672b9b. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+\n",
      "|name|maxPriceChange|\n",
      "+----+--------------+\n",
      "|PCLN|       1165.58|\n",
      "+----+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 423:====>         (62 + 8) / 200][Stage 424:>                (0 + 0) / 1]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import from_json, col, max, avg\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType\n",
    "import time\n",
    "\n",
    "\n",
    "# Assign watermarks\n",
    "df_with_watermark = df.withWatermark(\"timestamp\", \"5 minutes\")\n",
    "\n",
    "# Calculate the price change for each stock within the time window\n",
    "price_change = df_with_watermark.groupBy(\"name\").agg(max(col(\"price\")).alias(\"maxPriceChange\"))\n",
    "\n",
    "# Define the query with Complete output mode\n",
    "query1 = (price_change.writeStream\n",
    "    .outputMode(\"complete\")\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"MOST_GAINED_STOCK13\")\n",
    "    .start())\n",
    "\n",
    "# Allow the above query to populate some data\n",
    "time.sleep(60)\n",
    "\n",
    "# Fetch the stock with the maximum price change from the in-memory table\n",
    "result = spark.sql(f\"SELECT name, maxPriceChange FROM MOST_GAINED_STOCK13 ORDER BY maxPriceChange DESC LIMIT 1\")\n",
    "\n",
    "# Show the result\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e51aa2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/06 13:32:23 WARN StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-b1165f76-5b6f-4843-9ce3-57a8defa145e. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: LLY, Gain: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: TGT, Gain: 5.619999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: ADP, Gain: 6.0249999999999915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: GWW, Gain: 32.66999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: GWW, Gain: 32.66999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: GWW, Gain: 32.66999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: GWW, Gain: 32.66999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: PCLN, Gain: 162.14980000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: PCLN, Gain: 162.14980000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: PCLN, Gain: 183.45019999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: PCLN, Gain: 183.45019999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: PCLN, Gain: 183.45019999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: PCLN, Gain: 183.45019999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: PCLN, Gain: 183.45019999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: PCLN, Gain: 183.45019999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: PCLN, Gain: 183.45019999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: PCLN, Gain: 183.45019999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: PCLN, Gain: 183.45019999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: PCLN, Gain: 183.45019999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock with the maximum gain: PCLN, Gain: 183.45019999999988\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import window, col, last\n",
    "from pyspark.sql.types import StringType, DoubleType, StructType, StructField, TimestampType\n",
    "\n",
    "# Use a dictionary to hold the state of each stock\n",
    "stock_states = {}\n",
    "\n",
    "# Define a class to hold the state of each stock\n",
    "class StockState:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.last_price = None\n",
    "        self.max_gain = 0.0\n",
    "\n",
    "    def update(self, price):\n",
    "        if self.last_price is not None:\n",
    "            gain = price - self.last_price\n",
    "            if gain > self.max_gain:\n",
    "                self.max_gain = gain\n",
    "        self.last_price = price\n",
    "\n",
    "# Define the watermark and window operation on the streaming DataFrame\n",
    "windowedDF = df \\\n",
    "    .withWatermark(\"timestamp\", \"10 minutes\") \\\n",
    "    .groupBy(\n",
    "        col(\"name\"),\n",
    "        window(col(\"timestamp\"), \"5 minutes\")\n",
    "    ) \\\n",
    "    .agg(\n",
    "        last(\"price\").alias(\"last_price\")\n",
    "    )\n",
    "\n",
    "def process_batch(df, epoch_id):\n",
    "    # Process the DataFrame row by row\n",
    "    for row in df.collect():\n",
    "        stock_name = row['name']\n",
    "        price = row['last_price']\n",
    "\n",
    "        # Get the stock state or create it if it doesn't exist\n",
    "        stock_state = stock_states.get(stock_name, StockState(stock_name))\n",
    "\n",
    "        # Update the state\n",
    "        stock_state.update(price)\n",
    "        stock_states[stock_name] = stock_state  # Update the state in the dictionary\n",
    "\n",
    "    # Find the stock with the maximum gain\n",
    "    max_gain_stock = max(stock_states, key=lambda stock_name: stock_states[stock_name].max_gain)\n",
    "    max_gain = stock_states[max_gain_stock].max_gain\n",
    "\n",
    "    print(f\"Stock with the maximum gain: {max_gain_stock}, Gain: {max_gain}\")\n",
    "\n",
    "# Define the streaming query using the process_batch function\n",
    "query = windowedDF.writeStream \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .foreachBatch(process_batch) \\\n",
    "    .start()  # Start the streaming query\n",
    "\n",
    "# Await termination of the streaming query (this is running continuously)\n",
    "query.awaitTermination(timeout=60)\n",
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dd0527",
   "metadata": {},
   "source": [
    "## Implement a control that checks if a stock does not lose too much value in a period of time (feel free to choose the value you prefer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43741176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/06 19:40:42 WARN StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-6f5379f1-698b-428a-9050-f14cb3451ade. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock 'MRO' exceeded the maximum allowable percentage loss within the time window.\n",
      "Stock 'CMS' exceeded the maximum allowable percentage loss within the time window.\n",
      "Stock 'SCG' exceeded the maximum allowable percentage loss within the time window.\n",
      "Stock 'NEM' exceeded the maximum allowable percentage loss within the time window.\n",
      "Stock 'KR' exceeded the maximum allowable percentage loss within the time window.\n",
      "Stock 'RE' exceeded the maximum allowable percentage loss within the time window.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock 'UPS' exceeded the maximum allowable percentage loss within the time window.\n",
      "Stock 'KO' exceeded the maximum allowable percentage loss within the time window.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock 'DOV' exceeded the maximum allowable percentage loss within the time window.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock 'KMI' exceeded the maximum allowable percentage loss within the time window.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:===================================================>  (191 + 9) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock 'ULTA' exceeded the maximum allowable percentage loss within the time window.\n",
      "Stock 'ANSS' exceeded the maximum allowable percentage loss within the time window.\n",
      "Stock 'ZION' exceeded the maximum allowable percentage loss within the time window.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import window, col, last\n",
    "from pyspark.sql.types import StringType, DoubleType, StructType, StructField, TimestampType\n",
    "\n",
    "# Use a dictionary to hold the state of each stock\n",
    "stock_states = {}\n",
    "\n",
    "# Set to hold names of stocks that exceeded the maximum allowable percentage loss\n",
    "stocks_with_large_losses = set()\n",
    "\n",
    "# Define the maximum allowable percentage loss (e.g., 5%)\n",
    "max_allowable_percentage_loss = 5.0\n",
    "\n",
    "class StockState:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.last_price = None\n",
    "        self.last_window_end = None\n",
    "\n",
    "    def update(self, price, window_end):\n",
    "        if self.last_window_end is not None and window_end > self.last_window_end:\n",
    "            if self.last_price is not None:\n",
    "                price_change = price - self.last_price\n",
    "                percentage_loss = (price_change / self.last_price) * 100\n",
    "                if percentage_loss < -max_allowable_percentage_loss:\n",
    "                    stocks_with_large_losses.add(self.name)\n",
    "            self.last_price = price\n",
    "        self.last_window_end = window_end\n",
    "\n",
    "# Modify the watermark and window operation on the streaming DataFrame\n",
    "windowedDF = df \\\n",
    "    .withWatermark(\"timestamp\", \"10 minutes\") \\\n",
    "    .groupBy(\n",
    "        col(\"name\"),\n",
    "        window(col(\"timestamp\"), \"5 minutes\")\n",
    "    ) \\\n",
    "    .agg(\n",
    "        last(\"price\").alias(\"last_price\")\n",
    "    )\n",
    "\n",
    "def process_batch(df, epoch_id):\n",
    "    # Process the DataFrame row by row\n",
    "    for row in df.collect():\n",
    "        stock_name = row['name']\n",
    "        price = row['last_price']\n",
    "        window_end = row['window'].end\n",
    "\n",
    "        # Get the stock state or create it if it doesn't exist\n",
    "        stock_state = stock_states.get(stock_name, StockState(stock_name))\n",
    "\n",
    "        # Update the state and check for large percentage losses\n",
    "        stock_state.update(price, window_end)\n",
    "        stock_states[stock_name] = stock_state  # Update the state in the dictionary\n",
    "\n",
    "    # Log or take action on stocks with large losses\n",
    "    for stock in stocks_with_large_losses:\n",
    "        print(f\"Stock '{stock}' exceeded the maximum allowable percentage loss within the time window.\")\n",
    "    stocks_with_large_losses.clear()\n",
    "\n",
    "# Define the streaming query using the process_batch function\n",
    "query = windowedDF.writeStream \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .foreachBatch(process_batch) \\\n",
    "    .start()  # Start the streaming query\n",
    "\n",
    "# Await termination of the streaming query (this is running continuously)\n",
    "query.awaitTermination(timeout=60)\n",
    "query.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce9190",
   "metadata": {},
   "source": [
    "## Imagine you own some stocks (stored in a data frame with the schema <name,amount of stocks owned>). Compute how your asset changes with the fluctuation of the market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea011684",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/opt/workspace/your_stocks.csv;",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 26\u001b[0m\n\u001b[1;32m     21\u001b[0m stock_price_data \u001b[38;5;241m=\u001b[39m stock_price_streaming\u001b[38;5;241m.\u001b[39mselectExpr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAST(value AS STRING) as json\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;241m.\u001b[39mselectExpr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_json(json, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname STRING, price DOUBLE, timestamp TIMESTAMP\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) as parsed_value\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparsed_value.*\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Load the data frame with the amount of stocks you own\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m your_stocks \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myour_stocks.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Join the streaming DataFrame with your stocks data using 'name' as the common key\u001b[39;00m\n\u001b[1;32m     29\u001b[0m joined_data \u001b[38;5;241m=\u001b[39m stock_price_data\u001b[38;5;241m.\u001b[39mjoin(your_stocks, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/readwriter.py:535\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup)\u001b[0m\n\u001b[1;32m    533\u001b[0m     path \u001b[38;5;241m=\u001b[39m [path]\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/utils.py:137\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    133\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/opt/workspace/your_stocks.csv;"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import window, col, last, sum\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder.appName(\"AssetFluctuation\").getOrCreate()\n",
    "\n",
    "# Load stock price data as a streaming DataFrame\n",
    "stock_price_streaming = spark.readStream.format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka1:9092\") \\\n",
    "    .option(\"subscribe\", \"stock_prices\") \\\n",
    "    .load()\n",
    "\n",
    "# Define the schema for the streaming DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"price\", DoubleType(), True),\n",
    "    StructField(\"timestamp\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "# Parse the JSON value and select relevant columns\n",
    "stock_price_data = stock_price_streaming.selectExpr(\"CAST(value AS STRING) as json\") \\\n",
    "    .selectExpr(\"from_json(json, 'name STRING, price DOUBLE, timestamp TIMESTAMP') as parsed_value\") \\\n",
    "    .select(\"parsed_value.*\")\n",
    "\n",
    "# Load the data frame with the amount of stocks you own\n",
    "your_stocks = spark.read.csv(\"your_stocks.csv\", header=True, schema=schema)\n",
    "\n",
    "# Join the streaming DataFrame with your stocks data using 'name' as the common key\n",
    "joined_data = stock_price_data.join(your_stocks, \"name\")\n",
    "\n",
    "# Calculate the total value of your assets\n",
    "asset_value = joined_data.withColumn(\"asset_value\", col(\"price\") * col(\"amount\"))\n",
    "\n",
    "# Group by timestamp to calculate the sum of your assets over time\n",
    "agg_data = asset_value.groupBy(window(col(\"timestamp\"), \"5 minutes\")).agg(sum(\"asset_value\").alias(\"total_asset_value\"))\n",
    "\n",
    "# Define the query to write the results to an output sink (e.g., console)\n",
    "query = agg_data.writeStream.outputMode(\"update\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "# Await termination of the streaming query\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b62130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
